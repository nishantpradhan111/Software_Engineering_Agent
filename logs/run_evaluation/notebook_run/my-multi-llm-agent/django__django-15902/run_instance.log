2025-04-29 01:24:27,377 - INFO - Creating container for django__django-15902...
2025-04-29 01:24:28,110 - INFO - Container for django__django-15902 created: 8ee2883b5dd533d19b9341882f740cfc442e07e3a0859a1b0997d6beca97cc5c
2025-04-29 01:24:28,751 - INFO - Container for django__django-15902 started: 8ee2883b5dd533d19b9341882f740cfc442e07e3a0859a1b0997d6beca97cc5c
2025-04-29 01:24:28,753 - INFO - Intermediate patch for django__django-15902 written to logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\patch.diff, now applying to container...
2025-04-29 01:24:28,905 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 01:24:28,974 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 01:24:29,034 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-04-29 01:24:29,035 - INFO - >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

2025-04-29 01:24:29,130 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 01:24:29,130 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,130 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,133 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,133 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,133 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,133 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,135 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,139 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,139 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,139 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,139 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,141 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,143 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,143 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,143 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,143 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,143 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,145 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,145 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,145 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,145 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,147 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,150 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,153 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,153 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,153 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,154 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,159 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,163 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,165 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,170 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,172 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,175 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,175 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,175 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,177 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,177 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,177 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,177 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,179 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,179 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,180 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,180 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,180 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,182 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,182 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,184 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,185 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,185 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,185 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,187 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,187 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,187 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,189 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,189 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,217 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,217 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,217 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,218 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,219 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,219 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,219 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,219 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,226 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,226 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,227 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,299 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 01:24:29,300 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,300 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,301 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,301 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,301 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,301 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,302 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,302 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,302 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,302 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,303 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,303 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,303 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,303 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,304 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,304 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,304 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,304 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,305 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,305 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,305 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,306 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,306 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,306 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,306 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,306 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,307 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,307 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,307 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,307 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,308 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,308 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,308 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,309 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,309 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,309 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,309 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,309 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,310 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,310 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,310 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,311 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,311 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,311 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,311 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,311 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,312 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,312 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,312 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,313 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,314 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,314 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,314 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,314 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,315 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,316 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,317 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,317 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,317 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,317 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,318 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,318 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,318 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,318 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,319 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,320 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,320 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,320 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,320 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,320 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,321 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,321 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,321 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,322 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,322 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,322 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,322 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,323 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,323 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,324 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,324 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,325 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,325 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,325 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,325 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,326 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,326 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,327 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,327 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,327 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,327 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,328 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,328 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,328 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,328 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,329 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,329 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,329 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,330 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,330 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,331 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,333 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,335 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,337 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,337 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,337 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,337 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,337 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,339 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,342 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,342 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,342 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,342 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,342 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,344 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,344 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,344 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,344 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,345 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,348 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,348 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,348 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,350 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,350 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,350 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,350 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,350 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,351 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,351 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,351 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,351 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,351 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,352 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,354 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,356 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,356 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,356 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,356 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,356 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,358 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15902: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/renderers.py
Hunk #1 FAILED at 87.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/renderers.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-15902\run_instance.log) for more information.

2025-04-29 01:24:29,359 - INFO - Attempting to stop container sweb.eval.django__django-15902.notebook_run...
2025-04-29 01:24:45,171 - INFO - Attempting to remove container sweb.eval.django__django-15902.notebook_run...
2025-04-29 01:24:45,748 - INFO - Container sweb.eval.django__django-15902.notebook_run removed.
2025-04-29 01:24:45,749 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-15902:latest...
2025-04-29 01:24:49,858 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-15902:latest removed.
