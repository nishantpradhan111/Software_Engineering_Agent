2025-04-29 01:03:22,764 - INFO - Creating container for django__django-13933...
2025-04-29 01:03:22,944 - INFO - Container for django__django-13933 created: 52674eebee786de3d74705091196b4356ed257f8855b56e0eb0d8f4a916c65c1
2025-04-29 01:03:23,215 - INFO - Container for django__django-13933 started: 52674eebee786de3d74705091196b4356ed257f8855b56e0eb0d8f4a916c65c1
2025-04-29 01:03:23,215 - INFO - Intermediate patch for django__django-13933 written to logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\patch.diff, now applying to container...
2025-04-29 01:03:23,339 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 01:03:23,388 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 01:03:23,437 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-04-29 01:03:23,437 - INFO - >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,467 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,470 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,475 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13933: >>>>> Patch Apply Failed:
(Stripping trailing CRs from patch; use --binary to disable.)
patching file django/forms/models.py
Hunk #1 FAILED at 1170.
1 out of 1 hunk FAILED -- saving rejects to file django/forms/models.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run\my-multi-llm-agent\django__django-13933\run_instance.log) for more information.

2025-04-29 01:03:23,518 - INFO - Attempting to stop container sweb.eval.django__django-13933.notebook_run...
2025-04-29 01:03:39,533 - INFO - Attempting to remove container sweb.eval.django__django-13933.notebook_run...
2025-04-29 01:03:39,704 - INFO - Container sweb.eval.django__django-13933.notebook_run removed.
2025-04-29 01:03:39,705 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13933:latest...
2025-04-29 01:03:43,005 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13933:latest removed.
