2025-05-07 19:07:43,246 - INFO - Creating container for django__django-13710...
2025-05-07 19:07:43,983 - INFO - Container for django__django-13710 created: ad0153759be3716a24b418c1be560f7c9443241e10ae01d22044cf70a6eb52f5
2025-05-07 19:07:44,248 - INFO - Container for django__django-13710 started: ad0153759be3716a24b418c1be560f7c9443241e10ae01d22044cf70a6eb52f5
2025-05-07 19:07:44,253 - INFO - Intermediate patch for django__django-13710 written to logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/patch.diff, now applying to container...
2025-05-07 19:07:44,441 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-07 19:07:44,512 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-07 19:07:44,587 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-07 19:07:44,588 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

2025-05-07 19:07:44,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:07:44,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,940 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,940 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,940 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,941 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,941 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,941 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,941 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,942 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,942 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,942 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,942 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,943 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,943 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,943 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,943 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,944 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,944 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,945 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,945 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,945 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,946 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,946 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,946 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,947 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,947 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,947 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,947 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,948 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,948 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,948 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,948 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,949 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,949 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,949 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,949 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,950 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,950 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,950 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,951 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,951 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,951 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,952 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,952 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,952 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,952 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,953 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,953 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,953 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,955 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,955 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,955 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,956 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,956 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,956 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,957 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,957 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,958 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,958 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,963 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,963 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,963 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,971 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:44,971 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,395 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:07:45,396 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,397 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,397 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,398 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,398 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,399 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,399 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,400 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,400 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,401 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,401 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,402 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,402 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,403 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,403 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,404 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,404 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,404 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,405 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,405 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,406 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,406 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,408 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,408 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,409 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,409 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,410 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,410 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,411 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,411 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,412 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,412 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,413 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,413 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,414 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,414 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,415 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,415 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,416 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,416 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,417 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,417 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,417 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,418 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,418 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,419 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,419 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,420 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,420 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,421 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,421 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,421 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,422 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,423 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,424 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13710: >>>>> Patch Apply Failed:
patching file django/contrib/admin/options.py
Hunk #1 FAILED at 2041.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/options.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13710/run_instance.log) for more information.

2025-05-07 19:07:45,453 - INFO - Attempting to stop container sweb.eval.django__django-13710.trial_run_corrected_mode_4.5...
2025-05-07 19:08:00,986 - INFO - Attempting to remove container sweb.eval.django__django-13710.trial_run_corrected_mode_4.5...
2025-05-07 19:08:01,020 - INFO - Container sweb.eval.django__django-13710.trial_run_corrected_mode_4.5 removed.
2025-05-07 19:08:01,020 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13710:latest...
2025-05-07 19:08:01,592 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13710:latest removed.
