2025-05-07 19:13:55,725 - INFO - Creating container for django__django-15202...
2025-05-07 19:13:55,892 - INFO - Container for django__django-15202 created: 22df65e2f937e4a294f0a40859e4539a1cd2069c40bece9cab2048b18903f375
2025-05-07 19:13:56,161 - INFO - Container for django__django-15202 started: 22df65e2f937e4a294f0a40859e4539a1cd2069c40bece9cab2048b18903f375
2025-05-07 19:13:56,165 - INFO - Intermediate patch for django__django-15202 written to logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/patch.diff, now applying to container...
2025-05-07 19:13:56,335 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-07 19:13:56,407 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-07 19:13:56,474 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-07 19:13:56,475 - INFO - >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

2025-05-07 19:13:56,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:13:56,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,843 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,843 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,844 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,844 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,845 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,845 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,847 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,847 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,847 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,848 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,848 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,848 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,849 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,849 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,849 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,849 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,850 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,850 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,850 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,850 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,851 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,851 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,851 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,851 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,852 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,852 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,852 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,853 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,853 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,853 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,853 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,854 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,854 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,854 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,854 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,855 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,855 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:56,855 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,162 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:13:57,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,166 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,166 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,166 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,167 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,167 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,168 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,168 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,169 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,169 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,172 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,172 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,173 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,173 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,173 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,174 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,174 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,175 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,175 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,176 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,176 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,176 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,178 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,178 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,178 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,179 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,179 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,182 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,182 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,182 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,185 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,185 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,185 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,186 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,186 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,187 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,187 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,188 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,188 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,188 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,189 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,189 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,189 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,192 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,192 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,192 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,203 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,204 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,204 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15202: >>>>> Patch Apply Failed:
patching file django/core/validators.py
Hunk #1 FAILED at 136.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-15202/run_instance.log) for more information.

2025-05-07 19:13:57,206 - INFO - Attempting to stop container sweb.eval.django__django-15202.trial_run_corrected_mode_4.5...
2025-05-07 19:14:12,934 - INFO - Attempting to remove container sweb.eval.django__django-15202.trial_run_corrected_mode_4.5...
2025-05-07 19:14:12,964 - INFO - Container sweb.eval.django__django-15202.trial_run_corrected_mode_4.5 removed.
2025-05-07 19:14:12,965 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-15202:latest...
2025-05-07 19:14:13,554 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-15202:latest removed.
