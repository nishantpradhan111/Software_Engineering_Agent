2025-05-07 19:04:20,903 - INFO - Creating container for django__django-13220...
2025-05-07 19:04:21,015 - INFO - Container for django__django-13220 created: b2d335b4a46c2044e6fd023b960e61e792c3d635ffd431a7f677660cd5c4bc2c
2025-05-07 19:04:21,265 - INFO - Container for django__django-13220 started: b2d335b4a46c2044e6fd023b960e61e792c3d635ffd431a7f677660cd5c4bc2c
2025-05-07 19:04:21,271 - INFO - Intermediate patch for django__django-13220 written to logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/patch.diff, now applying to container...
2025-05-07 19:04:21,446 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-07 19:04:21,527 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-07 19:04:21,602 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-07 19:04:21,602 - INFO - >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

2025-05-07 19:04:21,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:04:21,941 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,945 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,948 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,950 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,951 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,952 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,953 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,953 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,954 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,955 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,956 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,957 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,957 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,957 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,958 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,958 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,959 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,960 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,961 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,962 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,963 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,964 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,965 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,966 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,967 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,968 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,969 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,970 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,972 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,972 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,973 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,973 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,974 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,974 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,974 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,975 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,975 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,975 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,976 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,976 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,976 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,976 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,977 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,977 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,978 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,979 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,979 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,979 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,980 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,980 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,982 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,982 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,983 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,983 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,983 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,983 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,984 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,984 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,984 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,985 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,985 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,986 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,986 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,986 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,987 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,987 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,988 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,989 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,990 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,991 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,991 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:21,999 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,000 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,000 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,001 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,001 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,001 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,001 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,002 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,002 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,002 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,003 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,003 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,003 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,004 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,004 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,004 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,004 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,005 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,005 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,005 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,005 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-07 19:04:22,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,367 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,367 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,367 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,376 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,376 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,377 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,377 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,378 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,378 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,378 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,379 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,379 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,380 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,380 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,380 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,381 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,381 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,381 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,382 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,382 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,382 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,383 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,383 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,383 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,384 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,384 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,385 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,385 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,386 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,386 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,387 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,387 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,387 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,388 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,388 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,388 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,389 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,389 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,389 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,389 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,390 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,390 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,390 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,390 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,391 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,391 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,391 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,392 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,392 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,393 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,393 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13220: >>>>> Patch Apply Failed:
patching file django/core/exceptions.py
Hunk #1 FAILED at 193.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/core/exceptions.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4.5/my-multi-llm-agent/django__django-13220/run_instance.log) for more information.

2025-05-07 19:04:22,393 - INFO - Attempting to stop container sweb.eval.django__django-13220.trial_run_corrected_mode_4.5...
2025-05-07 19:04:38,095 - INFO - Attempting to remove container sweb.eval.django__django-13220.trial_run_corrected_mode_4.5...
2025-05-07 19:04:38,125 - INFO - Container sweb.eval.django__django-13220.trial_run_corrected_mode_4.5 removed.
2025-05-07 19:04:38,126 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13220:latest...
2025-05-07 19:04:38,611 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13220:latest removed.
