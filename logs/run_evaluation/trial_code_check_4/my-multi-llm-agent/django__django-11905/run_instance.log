2025-05-08 17:11:49,362 - INFO - Creating container for django__django-11905...
2025-05-08 17:11:50,396 - INFO - Container for django__django-11905 created: df3b2a27a91304d54b46ce7dba0de47c05c99a89512b68017ff2430304d9de45
2025-05-08 17:11:50,864 - INFO - Container for django__django-11905 started: df3b2a27a91304d54b46ce7dba0de47c05c99a89512b68017ff2430304d9de45
2025-05-08 17:11:50,870 - INFO - Intermediate patch for django__django-11905 written to logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/patch.diff, now applying to container...
2025-05-08 17:11:51,131 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-08 17:11:51,243 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-08 17:11:51,320 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-08 17:11:51,321 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

2025-05-08 17:11:51,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 17:11:51,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,621 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 17:11:51,622 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,622 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,623 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,623 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,624 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,624 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,624 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,625 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,626 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,626 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,626 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,627 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,627 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,627 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,628 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,628 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,628 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,629 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,629 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,629 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,630 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,630 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,631 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,631 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,631 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,632 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,632 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,632 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,632 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,633 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,633 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,634 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,634 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,635 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,635 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_4/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 17:11:51,667 - INFO - Attempting to stop container sweb.eval.django__django-11905.trial_code_check_4...
2025-05-08 17:12:07,594 - INFO - Attempting to remove container sweb.eval.django__django-11905.trial_code_check_4...
2025-05-08 17:12:08,102 - INFO - Container sweb.eval.django__django-11905.trial_code_check_4 removed.
2025-05-08 17:12:08,103 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-11905:latest...
2025-05-08 17:12:09,271 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-11905:latest removed.
