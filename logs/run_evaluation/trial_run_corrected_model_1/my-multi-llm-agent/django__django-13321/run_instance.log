2025-05-03 23:54:26,805 - INFO - Creating container for django__django-13321...
2025-05-03 23:54:27,286 - INFO - Container for django__django-13321 created: 2ab6f6bafdb0c53012417504fb665e3a5721c03c70d33cf3c7f8474cbfbdb79f
2025-05-03 23:54:27,574 - INFO - Container for django__django-13321 started: 2ab6f6bafdb0c53012417504fb665e3a5721c03c70d33cf3c7f8474cbfbdb79f
2025-05-03 23:54:27,580 - INFO - Intermediate patch for django__django-13321 written to logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/patch.diff, now applying to container...
2025-05-03 23:54:27,743 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-03 23:54:27,813 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-03 23:54:27,873 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-03 23:54:27,874 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

2025-05-03 23:54:28,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:54:28,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,216 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,216 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,216 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,217 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,217 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,218 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,218 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,218 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,219 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,219 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,219 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,219 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,220 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,220 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,220 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,221 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,221 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,221 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,222 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,222 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,222 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,222 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,223 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,223 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,223 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,224 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,224 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,224 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,224 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,225 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,225 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,226 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,226 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,226 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,228 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,228 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,228 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,229 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,229 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,229 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,229 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,230 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,230 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,230 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,234 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,234 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,235 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,235 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,236 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,236 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,242 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,242 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,246 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,246 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,246 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,580 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:54:28,581 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,581 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,581 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,582 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,582 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,583 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,583 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,584 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,584 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,585 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,585 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,585 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,586 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,586 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,586 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,587 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,587 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,587 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,587 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,588 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,588 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,588 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,589 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,589 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,589 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,590 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,590 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,590 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,591 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,591 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,591 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,591 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,592 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,592 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,592 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,593 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,593 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,594 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,594 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,594 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,595 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,595 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,595 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,596 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,596 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,596 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,596 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,597 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,597 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,597 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,598 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,598 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,598 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,598 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,599 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,599 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,600 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,600 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,601 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,601 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,601 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,601 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,602 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,602 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,602 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,603 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,603 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,603 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,604 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,604 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,604 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,605 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,605 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,605 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,605 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,606 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,606 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,606 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,607 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,607 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,608 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,608 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,608 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,608 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,609 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,609 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,609 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,610 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,610 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,610 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,610 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,611 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,611 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,611 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,612 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,612 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,612 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,612 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,613 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,613 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,613 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,613 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,614 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,614 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,614 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,615 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,615 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,615 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,615 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,616 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,616 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,616 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,617 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,617 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,617 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,618 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,618 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,618 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,619 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,619 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,619 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,620 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 126.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-03 23:54:28,620 - INFO - Attempting to stop container sweb.eval.django__django-13321.trial_run_corrected_model_1...
2025-05-03 23:54:44,171 - INFO - Attempting to remove container sweb.eval.django__django-13321.trial_run_corrected_model_1...
2025-05-03 23:54:44,205 - INFO - Container sweb.eval.django__django-13321.trial_run_corrected_model_1 removed.
2025-05-03 23:54:44,206 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13321:latest...
2025-05-03 23:54:44,718 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13321:latest removed.
