2025-05-03 23:45:28,543 - INFO - Creating container for django__django-12983...
2025-05-03 23:45:28,978 - INFO - Container for django__django-12983 created: 8a1943afe8cd158d56c1dfc169cda91fdee64dc98f51239e5bfc5746dc994ca5
2025-05-03 23:45:29,282 - INFO - Container for django__django-12983 started: 8a1943afe8cd158d56c1dfc169cda91fdee64dc98f51239e5bfc5746dc994ca5
2025-05-03 23:45:29,287 - INFO - Intermediate patch for django__django-12983 written to logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/patch.diff, now applying to container...
2025-05-03 23:45:29,457 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-03 23:45:29,525 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-03 23:45:29,590 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-03 23:45:29,591 - INFO - >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

2025-05-03 23:45:29,903 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:45:29,903 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,905 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,905 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,905 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,906 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,906 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,921 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,921 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,925 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,925 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,925 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,932 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,932 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,932 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,936 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,937 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,938 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:29,939 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:45:30,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,248 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,248 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,248 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,249 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,249 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,249 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,250 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,250 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,251 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,251 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,251 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,253 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,253 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,253 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,254 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,254 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,254 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,254 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,264 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,264 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,264 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,266 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,266 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,267 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,267 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,267 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,269 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,271 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-03 23:45:30,286 - INFO - Attempting to stop container sweb.eval.django__django-12983.trial_run_corrected_model_1...
2025-05-03 23:45:45,745 - INFO - Attempting to remove container sweb.eval.django__django-12983.trial_run_corrected_model_1...
2025-05-03 23:45:45,796 - INFO - Container sweb.eval.django__django-12983.trial_run_corrected_model_1 removed.
2025-05-03 23:45:45,797 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-12983:latest...
2025-05-03 23:45:46,279 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-12983:latest removed.
