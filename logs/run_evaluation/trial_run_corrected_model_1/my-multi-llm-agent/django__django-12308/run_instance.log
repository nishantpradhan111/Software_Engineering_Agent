2025-05-03 23:37:36,264 - INFO - Creating container for django__django-12308...
2025-05-03 23:37:36,368 - INFO - Container for django__django-12308 created: cd662b07ae3fcf5f35bfdb4b374d88c4f0f9dac4e64ed7ea6d3ce38f99c4b92a
2025-05-03 23:37:36,621 - INFO - Container for django__django-12308 started: cd662b07ae3fcf5f35bfdb4b374d88c4f0f9dac4e64ed7ea6d3ce38f99c4b92a
2025-05-03 23:37:36,629 - INFO - Intermediate patch for django__django-12308 written to logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/patch.diff, now applying to container...
2025-05-03 23:37:36,803 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-03 23:37:36,880 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-03 23:37:36,956 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-03 23:37:36,957 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

2025-05-03 23:37:37,127 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:37:37,127 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,128 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,128 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,128 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,129 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,129 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,129 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,130 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,130 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,131 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,132 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,132 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,132 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,133 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,133 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,133 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,134 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,134 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,134 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,135 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,135 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,135 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,136 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,136 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,136 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,137 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,137 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,138 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,138 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,138 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,139 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,139 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,139 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,140 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,140 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,140 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,141 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,141 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,141 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,142 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,142 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,142 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,143 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,143 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,144 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,144 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,145 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,146 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,147 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,147 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,148 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,149 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,149 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,150 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,150 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,150 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,151 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,151 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,151 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,151 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,152 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,152 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,152 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,152 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,153 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,153 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,153 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,154 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,154 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,154 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,155 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,155 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,155 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,156 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,156 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,156 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,157 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,157 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,158 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,158 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,158 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,159 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,159 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,159 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,160 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,160 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,160 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,161 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,161 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,162 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,162 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,163 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,164 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,165 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,166 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,166 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,167 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,167 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,167 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,168 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,168 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,168 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,169 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,169 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,169 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,170 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,171 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,172 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,172 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,172 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,173 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 23:37:37,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 401.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_1/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-03 23:37:37,490 - INFO - Attempting to stop container sweb.eval.django__django-12308.trial_run_corrected_model_1...
2025-05-03 23:37:53,011 - INFO - Attempting to remove container sweb.eval.django__django-12308.trial_run_corrected_model_1...
2025-05-03 23:37:53,467 - INFO - Container sweb.eval.django__django-12308.trial_run_corrected_model_1 removed.
2025-05-03 23:37:53,468 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-12308:latest...
2025-05-03 23:37:54,000 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-12308:latest removed.
