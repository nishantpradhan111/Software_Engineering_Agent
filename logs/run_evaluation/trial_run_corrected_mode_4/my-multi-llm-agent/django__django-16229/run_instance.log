2025-05-04 17:20:48,486 - INFO - Creating container for django__django-16229...
2025-05-04 17:20:49,251 - INFO - Container for django__django-16229 created: 47ea480b3c352495707764046c137d0968ff4bc3d0b84d08c68bbb6199fd9059
2025-05-04 17:20:49,619 - INFO - Container for django__django-16229 started: 47ea480b3c352495707764046c137d0968ff4bc3d0b84d08c68bbb6199fd9059
2025-05-04 17:20:49,626 - INFO - Intermediate patch for django__django-16229 written to logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/patch.diff, now applying to container...
2025-05-04 17:20:49,858 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 17:20:49,944 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 17:20:50,013 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 17:20:50,014 - INFO - >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

2025-05-04 17:20:50,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 17:20:50,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,341 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,341 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,367 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,367 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,368 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,369 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,370 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,371 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,372 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,373 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,374 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,375 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,691 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 17:20:50,692 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,692 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,692 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,692 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,693 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,693 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,693 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,694 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,694 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,694 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,694 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,695 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,695 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,695 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,695 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,696 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,696 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,696 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,696 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,697 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,697 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,697 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,697 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,698 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,698 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,698 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,698 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,699 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,699 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,699 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,700 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,700 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,700 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,700 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,701 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,701 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,701 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,702 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,702 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,702 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,702 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,702 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,703 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,703 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,703 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,703 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,704 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,704 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,704 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,704 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,705 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,705 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,705 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,706 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,706 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,706 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,707 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,707 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,707 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,707 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,708 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,708 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,708 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,709 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,709 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,709 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,709 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,710 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,710 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,710 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,710 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,711 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,711 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,712 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,712 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,712 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,713 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,713 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,713 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,714 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,714 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,714 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,715 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,715 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,715 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,716 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,716 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,716 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,717 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,717 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,718 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,718 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,718 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,718 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,719 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,719 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,719 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,720 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,720 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,720 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,721 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,721 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,721 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,721 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,722 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,722 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,722 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,723 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,723 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,724 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,724 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,724 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,725 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,725 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,726 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,726 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,726 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,727 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,727 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,728 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,728 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,729 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16229: >>>>> Patch Apply Failed:
patching file django/forms/boundfield.py
Hunk #1 FAILED at 96.
Hunk #2 succeeded at 96 with fuzz 3 (offset -8 lines).
patch unexpectedly ends in middle of line
1 out of 2 hunks FAILED -- saving rejects to file django/forms/boundfield.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-16229/run_instance.log) for more information.

2025-05-04 17:20:50,729 - INFO - Attempting to stop container sweb.eval.django__django-16229.trial_run_corrected_mode_4...
2025-05-04 17:21:06,322 - INFO - Attempting to remove container sweb.eval.django__django-16229.trial_run_corrected_mode_4...
2025-05-04 17:21:06,351 - INFO - Container sweb.eval.django__django-16229.trial_run_corrected_mode_4 removed.
2025-05-04 17:21:06,352 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-16229:latest...
2025-05-04 17:21:06,903 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-16229:latest removed.
