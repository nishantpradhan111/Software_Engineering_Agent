2025-05-04 17:12:07,993 - INFO - Creating container for django__django-15213...
2025-05-04 17:12:08,716 - INFO - Container for django__django-15213 created: 7c7a7afef6b5ddc42c8a4db7258f9e8476a08da9598194d2421f3ac4a3033278
2025-05-04 17:12:08,961 - INFO - Container for django__django-15213 started: 7c7a7afef6b5ddc42c8a4db7258f9e8476a08da9598194d2421f3ac4a3033278
2025-05-04 17:12:08,966 - INFO - Intermediate patch for django__django-15213 written to logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/patch.diff, now applying to container...
2025-05-04 17:12:09,166 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 17:12:09,247 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 17:12:09,325 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 17:12:09,325 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

2025-05-04 17:12:09,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 17:12:09,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,493 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,493 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,493 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,495 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,495 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,495 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,499 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,500 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,500 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,500 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,508 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,508 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,508 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,514 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,514 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,514 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 17:12:09,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15213: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 994.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-15213/run_instance.log) for more information.

2025-05-04 17:12:09,682 - INFO - Attempting to stop container sweb.eval.django__django-15213.trial_run_corrected_mode_4...
2025-05-04 17:12:25,261 - INFO - Attempting to remove container sweb.eval.django__django-15213.trial_run_corrected_mode_4...
2025-05-04 17:12:25,291 - INFO - Container sweb.eval.django__django-15213.trial_run_corrected_mode_4 removed.
2025-05-04 17:12:25,292 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-15213:latest...
2025-05-04 17:12:25,887 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-15213:latest removed.
