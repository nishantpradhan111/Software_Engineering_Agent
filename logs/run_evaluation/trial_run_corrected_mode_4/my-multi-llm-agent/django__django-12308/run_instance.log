2025-05-04 16:48:52,591 - INFO - Creating container for django__django-12308...
2025-05-04 16:48:53,549 - INFO - Container for django__django-12308 created: dc72a98ab78e634e52b1c40e308c39118e60eadc7586e0e5d0b0cd7e984be67f
2025-05-04 16:48:54,121 - INFO - Container for django__django-12308 started: dc72a98ab78e634e52b1c40e308c39118e60eadc7586e0e5d0b0cd7e984be67f
2025-05-04 16:48:54,128 - INFO - Intermediate patch for django__django-12308 written to logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/patch.diff, now applying to container...
2025-05-04 16:48:54,340 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 16:48:54,419 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 16:48:54,492 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 16:48:54,492 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

2025-05-04 16:48:54,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 16:48:54,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,687 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,687 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,687 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,809 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 16:48:54,810 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,810 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,810 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,811 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,811 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,811 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,812 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,812 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,812 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,813 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,813 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,813 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,813 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,815 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,815 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,815 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,843 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,843 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,843 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,844 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,844 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,844 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,845 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,845 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,845 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,846 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12308: >>>>> Patch Apply Failed:
patching file django/contrib/admin/utils.py
Hunk #1 FAILED at 400.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/admin/utils.py.rej
patching file tests/admin_utils/tests.py
Hunk #1 FAILED at 181.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/admin_utils/tests.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_4/my-multi-llm-agent/django__django-12308/run_instance.log) for more information.

2025-05-04 16:48:54,847 - INFO - Attempting to stop container sweb.eval.django__django-12308.trial_run_corrected_mode_4...
2025-05-04 16:49:10,634 - INFO - Attempting to remove container sweb.eval.django__django-12308.trial_run_corrected_mode_4...
2025-05-04 16:49:10,969 - INFO - Container sweb.eval.django__django-12308.trial_run_corrected_mode_4 removed.
2025-05-04 16:49:10,969 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-12308:latest...
2025-05-04 16:49:11,843 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-12308:latest removed.
