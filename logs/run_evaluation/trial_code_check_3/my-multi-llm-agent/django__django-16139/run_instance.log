2025-05-08 16:56:31,931 - INFO - Creating container for django__django-16139...
2025-05-08 16:56:32,700 - INFO - Container for django__django-16139 created: 13d9043cb2580a7cfb31990273c16afe43f79411d29c10ea7c4577974be250d8
2025-05-08 16:56:32,997 - INFO - Container for django__django-16139 started: 13d9043cb2580a7cfb31990273c16afe43f79411d29c10ea7c4577974be250d8
2025-05-08 16:56:33,002 - INFO - Intermediate patch for django__django-16139 written to logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/patch.diff, now applying to container...
2025-05-08 16:56:33,172 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-08 16:56:33,240 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-08 16:56:33,307 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-08 16:56:33,307 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

2025-05-08 16:56:33,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 16:56:33,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:33,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,014 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 16:56:34,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,016 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,016 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,017 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,017 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,037 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,037 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,037 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,042 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,042 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,043 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,044 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,044 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,044 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,045 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,045 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,045 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,046 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,046 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,046 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,046 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,047 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,047 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,047 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,048 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,048 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,048 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,049 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,049 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,049 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,049 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,050 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,050 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,050 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,051 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,051 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,051 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,052 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,052 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,052 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,052 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,053 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,053 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-08 16:56:34,054 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 260.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

