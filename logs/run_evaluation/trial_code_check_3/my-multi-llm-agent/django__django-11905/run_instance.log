2025-05-08 16:56:24,451 - INFO - Creating container for django__django-11905...
2025-05-08 16:56:25,218 - INFO - Container for django__django-11905 created: 36ed9ffaed53933ad51df64c94028e93dbd9068622a46d7c4c224c0b15159204
2025-05-08 16:56:25,668 - INFO - Container for django__django-11905 started: 36ed9ffaed53933ad51df64c94028e93dbd9068622a46d7c4c224c0b15159204
2025-05-08 16:56:25,676 - INFO - Intermediate patch for django__django-11905 written to logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/patch.diff, now applying to container...
2025-05-08 16:56:25,899 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-08 16:56:26,000 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-08 16:56:26,078 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-08 16:56:26,078 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

2025-05-08 16:56:26,226 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 16:56:26,226 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,227 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,228 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,228 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,229 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,230 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,231 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,232 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,233 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,234 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,234 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,235 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,235 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,236 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,236 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,236 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,237 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,238 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,239 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,240 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,241 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,242 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,242 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,242 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,248 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,249 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,251 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,253 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,264 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,264 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,265 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,266 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,266 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,266 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,267 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,267 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,269 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,269 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,269 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,270 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,270 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,270 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,271 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,271 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,275 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 16:56:26,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,463 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,481 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,482 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,483 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,484 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,485 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,486 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,487 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,488 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,489 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,490 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,491 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,492 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,493 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,493 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,494 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,495 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,495 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,496 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,497 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,498 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,499 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,499 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,499 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,499 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,500 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,502 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,503 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,508 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,510 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

2025-05-08 16:56:26,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11905: >>>>> Patch Apply Failed:
patching file django/db/models/lookups.py
Hunk #1 FAILED at 463.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/lookups.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_code_check_3/my-multi-llm-agent/django__django-11905/run_instance.log) for more information.

