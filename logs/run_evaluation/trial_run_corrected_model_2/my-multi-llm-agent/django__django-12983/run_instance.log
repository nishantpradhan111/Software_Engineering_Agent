2025-05-04 09:43:57,286 - INFO - Creating container for django__django-12983...
2025-05-04 09:43:57,772 - INFO - Container for django__django-12983 created: ce5da6a0a59b03a2d3848339701d0c62b615e3ff01c667fc9727147eb48c5c6c
2025-05-04 09:43:58,024 - INFO - Container for django__django-12983 started: ce5da6a0a59b03a2d3848339701d0c62b615e3ff01c667fc9727147eb48c5c6c
2025-05-04 09:43:58,029 - INFO - Intermediate patch for django__django-12983 written to logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/patch.diff, now applying to container...
2025-05-04 09:43:58,197 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 09:43:58,263 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 09:43:58,328 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 09:43:58,329 - INFO - >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

2025-05-04 09:43:58,635 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 09:43:58,635 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,636 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,637 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,638 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,639 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,640 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,641 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,642 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,643 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,644 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,645 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,646 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,647 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,648 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,649 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,650 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,651 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,652 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,653 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,654 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:58,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 09:43:59,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,006 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,007 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,007 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,007 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,007 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,008 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,008 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,008 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,009 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,009 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,010 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,010 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,010 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,011 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,011 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,011 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,012 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,012 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,012 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,012 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,012 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,013 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,013 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,014 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,014 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,014 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,014 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,015 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,016 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,016 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,017 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,017 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,017 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,018 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,019 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,020 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,021 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,022 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,023 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,024 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,025 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,026 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,027 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,028 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,029 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,030 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,031 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,032 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,033 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,034 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,035 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,036 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,037 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,037 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,038 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,039 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,040 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,041 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,042 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,042 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,042 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file django/utils/text.py
Hunk #1 FAILED at 393.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/utils/text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-04 09:43:59,043 - INFO - Attempting to stop container sweb.eval.django__django-12983.trial_run_corrected_model_2...
2025-05-04 09:44:14,548 - INFO - Attempting to remove container sweb.eval.django__django-12983.trial_run_corrected_model_2...
2025-05-04 09:44:14,581 - INFO - Container sweb.eval.django__django-12983.trial_run_corrected_model_2 removed.
2025-05-04 09:44:14,581 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-12983:latest...
2025-05-04 09:44:15,122 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-12983:latest removed.
