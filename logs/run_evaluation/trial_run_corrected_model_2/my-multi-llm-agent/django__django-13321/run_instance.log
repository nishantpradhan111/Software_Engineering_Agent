2025-05-04 09:46:40,985 - INFO - Creating container for django__django-13321...
2025-05-04 09:46:41,249 - INFO - Container for django__django-13321 created: effa74e210341a4df8200a5449a2164388bf0c6af6aad6dcaf0a67180a739693
2025-05-04 09:46:41,513 - INFO - Container for django__django-13321 started: effa74e210341a4df8200a5449a2164388bf0c6af6aad6dcaf0a67180a739693
2025-05-04 09:46:41,523 - INFO - Intermediate patch for django__django-13321 written to logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/patch.diff, now applying to container...
2025-05-04 09:46:41,718 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 09:46:41,788 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 09:46:41,856 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 09:46:41,856 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

2025-05-04 09:46:42,173 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 09:46:42,174 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,174 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,175 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,175 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,176 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,176 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,177 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,178 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,178 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,179 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,179 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,179 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,180 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,181 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,182 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,182 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,183 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,184 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,185 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,185 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,186 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,189 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,190 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,191 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,192 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,192 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,193 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,194 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,195 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,196 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,197 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,198 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,199 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,200 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,201 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,202 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,203 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,203 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,203 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,203 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,204 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,204 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,204 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,205 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,206 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,207 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,207 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,207 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,208 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,208 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,208 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,209 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,210 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,211 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,212 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,213 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,214 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,215 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,525 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 09:46:42,525 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,526 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,526 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,526 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,528 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,528 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,528 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,529 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,529 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,529 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,530 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,530 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,530 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,530 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,531 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,531 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,532 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,532 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,532 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,533 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,533 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,533 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,534 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,534 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,534 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,535 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,535 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,535 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,538 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,538 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,538 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,539 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,539 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,539 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,542 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,542 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,542 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,544 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,544 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,544 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,550 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,550 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,555 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,555 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,555 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,558 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,558 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,558 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,559 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,559 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,559 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,560 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,560 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,560 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,561 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,561 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,561 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,562 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 121.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-13321/run_instance.log) for more information.

2025-05-04 09:46:42,562 - INFO - Attempting to stop container sweb.eval.django__django-13321.trial_run_corrected_model_2...
2025-05-04 09:46:58,367 - INFO - Attempting to remove container sweb.eval.django__django-13321.trial_run_corrected_model_2...
2025-05-04 09:46:58,399 - INFO - Container sweb.eval.django__django-13321.trial_run_corrected_model_2 removed.
2025-05-04 09:46:58,399 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13321:latest...
2025-05-04 09:46:58,956 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13321:latest removed.
