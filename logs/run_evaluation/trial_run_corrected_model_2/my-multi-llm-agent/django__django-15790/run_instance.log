2025-05-04 10:05:58,221 - INFO - Creating container for django__django-15790...
2025-05-04 10:05:58,574 - INFO - Container for django__django-15790 created: 0c566dfca0ddf7b306ab7ca209b44cad7957cc6e5f58cb0869885ed39df68645
2025-05-04 10:05:58,823 - INFO - Container for django__django-15790 started: 0c566dfca0ddf7b306ab7ca209b44cad7957cc6e5f58cb0869885ed39df68645
2025-05-04 10:05:58,828 - INFO - Intermediate patch for django__django-15790 written to logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/patch.diff, now applying to container...
2025-05-04 10:05:58,993 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 10:05:59,060 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 10:05:59,129 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 10:05:59,129 - INFO - >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


2025-05-04 10:05:59,425 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 10:05:59,425 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,425 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,426 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,426 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,426 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,426 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,427 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,427 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,427 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,427 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,438 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,456 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,457 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,458 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,767 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 10:05:59,768 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,768 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,768 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,769 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,769 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,769 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,769 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,770 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,770 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,771 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,771 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,771 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,771 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,772 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,772 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,772 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,772 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,774 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,774 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,774 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,775 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,775 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,775 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,778 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,778 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,778 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,778 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,781 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,781 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,783 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,783 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,783 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,783 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,784 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,784 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,784 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,784 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,786 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,786 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,786 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,786 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,787 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,787 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,787 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,789 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,789 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,789 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,789 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,790 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,790 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,790 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,791 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,791 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,791 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,791 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,792 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,792 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,792 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,792 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,793 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,793 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,794 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,795 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,795 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,796 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,796 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,796 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,797 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,797 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,797 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,798 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,798 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,799 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,800 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,800 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,801 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,801 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,802 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,802 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,803 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,804 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,804 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,804 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,805 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,805 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,805 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-15790: >>>>> Patch Apply Failed:
patching file django/core/checks/templates.py
Hunk #1 FAILED at 5.
Hunk #2 succeeded at 50 (offset 34 lines).
patch: **** malformed patch at line 70:      if settings.DEBUG and settings.TEMPLATE_DEBUG is False:


Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-15790/run_instance.log) for more information.

2025-05-04 10:05:59,810 - INFO - Attempting to stop container sweb.eval.django__django-15790.trial_run_corrected_model_2...
2025-05-04 10:06:15,385 - INFO - Attempting to remove container sweb.eval.django__django-15790.trial_run_corrected_model_2...
2025-05-04 10:06:15,422 - INFO - Container sweb.eval.django__django-15790.trial_run_corrected_model_2 removed.
2025-05-04 10:06:15,422 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-15790:latest...
2025-05-04 10:06:15,955 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-15790:latest removed.
