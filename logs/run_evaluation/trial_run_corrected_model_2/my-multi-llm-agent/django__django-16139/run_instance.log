2025-05-04 10:09:14,369 - INFO - Creating container for django__django-16139...
2025-05-04 10:09:14,575 - INFO - Container for django__django-16139 created: eda314f04bdce735d6c036d033933a03a2124d86feeba50d1c8a4357d7d5057a
2025-05-04 10:09:14,791 - INFO - Container for django__django-16139 started: eda314f04bdce735d6c036d033933a03a2124d86feeba50d1c8a4357d7d5057a
2025-05-04 10:09:14,797 - INFO - Intermediate patch for django__django-16139 written to logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/patch.diff, now applying to container...
2025-05-04 10:09:14,943 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-04 10:09:15,009 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-04 10:09:15,072 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-04 10:09:15,073 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

2025-05-04 10:09:15,333 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 10:09:15,333 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,333 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,334 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,334 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,334 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,335 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,335 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,335 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,335 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,336 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,336 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,337 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,337 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,337 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,337 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,338 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,338 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,338 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,338 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,339 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,340 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,341 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,341 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,341 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,342 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,343 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,344 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,345 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,346 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,347 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,348 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,349 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,350 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,351 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,352 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,353 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,354 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,355 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,356 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,357 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,358 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,359 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,360 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,361 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,362 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,363 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,364 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,365 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,366 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,655 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-04 10:09:15,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,656 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,657 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,658 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,659 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,660 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,661 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,662 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,663 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,664 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,665 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,666 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,667 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,668 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,669 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,670 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,671 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,672 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,673 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,674 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,675 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,676 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,677 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,678 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,679 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,680 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,681 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,682 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,683 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,684 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,685 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,686 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,687 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,687 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-16139: >>>>> Patch Apply Failed:
patching file django/contrib/auth/forms.py
Hunk #1 FAILED at 163.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/forms.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_model_2/my-multi-llm-agent/django__django-16139/run_instance.log) for more information.

2025-05-04 10:09:15,688 - INFO - Attempting to stop container sweb.eval.django__django-16139.trial_run_corrected_model_2...
2025-05-04 10:09:31,227 - INFO - Attempting to remove container sweb.eval.django__django-16139.trial_run_corrected_model_2...
2025-05-04 10:09:31,259 - INFO - Container sweb.eval.django__django-16139.trial_run_corrected_model_2 removed.
2025-05-04 10:09:31,260 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-16139:latest...
2025-05-04 10:09:31,804 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-16139:latest removed.
