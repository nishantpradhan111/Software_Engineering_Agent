2025-04-29 13:21:51,349 - INFO - Creating container for django__django-11964...
2025-04-29 13:21:51,647 - INFO - Container for django__django-11964 created: c3629ba03741f7c25fc047c5b141b505fefda450e69968af0403ed7db8e3e779
2025-04-29 13:21:51,893 - INFO - Container for django__django-11964 started: c3629ba03741f7c25fc047c5b141b505fefda450e69968af0403ed7db8e3e779
2025-04-29 13:21:51,896 - INFO - Intermediate patch for django__django-11964 written to logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\patch.diff, now applying to container...
2025-04-29 13:21:52,035 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 13:21:52,094 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 13:21:52,160 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 13:21:52,160 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

2025-04-29 13:21:52,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,225 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:21:52,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,289 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,292 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,293 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,294 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,295 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,295 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,295 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,295 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,295 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,296 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,296 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,296 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,296 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,296 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,297 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11964: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 1717 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11964\run_instance.log) for more information.

2025-04-29 13:21:52,298 - INFO - Attempting to stop container sweb.eval.django__django-11964.notebook_run_2...
2025-04-29 13:22:08,131 - INFO - Attempting to remove container sweb.eval.django__django-11964.notebook_run_2...
2025-04-29 13:22:08,173 - INFO - Container sweb.eval.django__django-11964.notebook_run_2 removed.
2025-04-29 13:22:08,174 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-11964:latest...
2025-04-29 13:22:08,967 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-11964:latest removed.
