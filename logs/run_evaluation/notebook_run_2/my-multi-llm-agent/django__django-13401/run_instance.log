2025-04-29 13:29:41,662 - INFO - Creating container for django__django-13401...
2025-04-29 13:29:42,290 - INFO - Container for django__django-13401 created: e9e25a306f9cb9a8166a961479a8784ec935efd0fe72837eb98b356ce885df64
2025-04-29 13:29:42,577 - INFO - Container for django__django-13401 started: e9e25a306f9cb9a8166a961479a8784ec935efd0fe72837eb98b356ce885df64
2025-04-29 13:29:42,578 - INFO - Intermediate patch for django__django-13401 written to logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\patch.diff, now applying to container...
2025-04-29 13:29:42,737 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 13:29:42,804 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 13:29:42,873 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 13:29:42,873 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

2025-04-29 13:29:42,911 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:29:42,911 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,912 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,913 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,914 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,915 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,916 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,917 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,917 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,917 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,918 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,918 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,918 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,918 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,918 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,919 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,920 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,920 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,920 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,920 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,920 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,921 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,922 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,922 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,922 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,922 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,923 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,924 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,925 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,926 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,927 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,927 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,927 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,928 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,928 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,928 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,928 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,929 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,929 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,929 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,929 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,929 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,930 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,931 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,931 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,931 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,932 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,932 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,932 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,933 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,933 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,933 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,933 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,933 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,934 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,935 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,936 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,937 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,938 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,939 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,939 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,939 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,940 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,941 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,941 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,941 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,941 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,971 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,973 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,974 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,975 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,977 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,978 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,980 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,981 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,982 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,984 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,985 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,986 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13401: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 198 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13401\run_instance.log) for more information.

2025-04-29 13:29:42,987 - INFO - Attempting to stop container sweb.eval.django__django-13401.notebook_run_2...
2025-04-29 13:29:58,597 - INFO - Attempting to remove container sweb.eval.django__django-13401.notebook_run_2...
2025-04-29 13:29:58,628 - INFO - Container sweb.eval.django__django-13401.notebook_run_2 removed.
2025-04-29 13:29:58,629 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13401:latest...
2025-04-29 13:29:59,301 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13401:latest removed.
