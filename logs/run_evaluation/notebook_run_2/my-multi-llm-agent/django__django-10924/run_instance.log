2025-04-29 13:16:53,347 - INFO - Creating container for django__django-10924...
2025-04-29 13:16:53,802 - INFO - Container for django__django-10924 created: 7edd9887693d2a48109cdf74e00b0dc6c2bf424f151b88205a2bc082f9714474
2025-04-29 13:16:54,088 - INFO - Container for django__django-10924 started: 7edd9887693d2a48109cdf74e00b0dc6c2bf424f151b88205a2bc082f9714474
2025-04-29 13:16:54,090 - INFO - Intermediate patch for django__django-10924 written to logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\patch.diff, now applying to container...
2025-04-29 13:16:54,250 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 13:16:54,319 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 13:16:54,383 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 13:16:54,384 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

2025-04-29 13:16:54,425 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:16:54,426 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,426 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,429 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,429 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,429 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,429 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,433 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,433 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,433 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,435 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,435 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,435 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,435 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,435 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,443 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,445 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,445 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,448 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,448 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,448 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,449 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,449 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,449 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,449 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,449 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,451 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,451 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,451 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,451 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,451 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,452 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,452 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,452 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,452 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,453 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,453 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,453 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,455 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,455 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,455 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,455 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,455 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,456 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,456 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,456 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,456 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,457 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,457 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,457 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,457 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,458 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,458 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,458 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,459 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,460 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,461 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,461 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,461 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,461 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,461 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,462 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,464 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,465 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-10924: >>>>> Patch Apply Failed:
patching file django/db/models/fields/files.py
Hunk #1 FAILED at 362 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/files.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-10924\run_instance.log) for more information.

2025-04-29 13:16:54,552 - INFO - Attempting to stop container sweb.eval.django__django-10924.notebook_run_2...
2025-04-29 13:17:10,273 - INFO - Attempting to remove container sweb.eval.django__django-10924.notebook_run_2...
2025-04-29 13:17:10,308 - INFO - Container sweb.eval.django__django-10924.notebook_run_2 removed.
2025-04-29 13:17:10,308 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-10924:latest...
2025-04-29 13:17:10,973 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-10924:latest removed.
