2025-04-29 13:19:39,691 - INFO - Creating container for django__django-11422...
2025-04-29 13:19:39,890 - INFO - Container for django__django-11422 created: 38a556c55dffcdad2def5c3a18a2c4dc0c9aa9d2a2ef2c0c86647ddb41b45946
2025-04-29 13:19:40,154 - INFO - Container for django__django-11422 started: 38a556c55dffcdad2def5c3a18a2c4dc0c9aa9d2a2ef2c0c86647ddb41b45946
2025-04-29 13:19:40,156 - INFO - Intermediate patch for django__django-11422 written to logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\patch.diff, now applying to container...
2025-04-29 13:19:40,325 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 13:19:40,399 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 13:19:40,464 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 13:19:40,464 - INFO - >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

2025-04-29 13:19:40,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:19:40,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,520 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,521 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,521 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,521 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,521 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,524 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,525 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,529 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,530 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,531 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,532 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,533 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,536 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,537 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,538 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,539 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,540 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,541 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,542 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,543 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,544 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,545 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,546 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,547 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,548 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,549 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,550 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,551 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,552 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,553 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,553 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,586 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,587 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,588 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,589 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,590 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,591 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,591 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,591 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,591 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,591 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,592 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,593 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,594 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,595 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,596 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,597 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,598 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,599 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,600 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,602 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,603 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,604 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11422: >>>>> Patch Apply Failed:
patching file django/utils/autoreload.py
Hunk #1 FAILED at 123 (different line endings).
Hunk #2 succeeded at 188 with fuzz 3.
Hunk #3 FAILED at 210 (different line endings).
2 out of 3 hunks FAILED -- saving rejects to file django/utils/autoreload.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-11422\run_instance.log) for more information.

2025-04-29 13:19:40,605 - INFO - Attempting to stop container sweb.eval.django__django-11422.notebook_run_2...
2025-04-29 13:19:56,185 - INFO - Attempting to remove container sweb.eval.django__django-11422.notebook_run_2...
2025-04-29 13:19:56,208 - INFO - Container sweb.eval.django__django-11422.notebook_run_2 removed.
2025-04-29 13:19:56,208 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-11422:latest...
2025-04-29 13:19:56,804 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-11422:latest removed.
