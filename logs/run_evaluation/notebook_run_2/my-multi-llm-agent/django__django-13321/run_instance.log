2025-04-29 13:29:16,565 - INFO - Creating container for django__django-13321...
2025-04-29 13:29:16,676 - INFO - Container for django__django-13321 created: a1da24b6ab10f61feb5fcc2ecc804381fb2b1679a2d7aebd33c133586435b629
2025-04-29 13:29:16,887 - INFO - Container for django__django-13321 started: a1da24b6ab10f61feb5fcc2ecc804381fb2b1679a2d7aebd33c133586435b629
2025-04-29 13:29:16,888 - INFO - Intermediate patch for django__django-13321 written to logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\patch.diff, now applying to container...
2025-04-29 13:29:17,026 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 13:29:17,093 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 13:29:17,154 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 13:29:17,155 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

2025-04-29 13:29:17,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:29:17,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,192 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,192 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,192 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,208 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,210 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,212 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 13:29:17,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,256 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,256 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,256 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,262 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,263 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,265 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,269 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,269 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,269 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13321: >>>>> Patch Apply Failed:
patching file django/contrib/sessions/backends/base.py
Hunk #1 FAILED at 123 (different line endings).
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/sessions/backends/base.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_2\my-multi-llm-agent\django__django-13321\run_instance.log) for more information.

2025-04-29 13:29:17,276 - INFO - Attempting to stop container sweb.eval.django__django-13321.notebook_run_2...
2025-04-29 13:29:32,780 - INFO - Attempting to remove container sweb.eval.django__django-13321.notebook_run_2...
2025-04-29 13:29:32,808 - INFO - Container sweb.eval.django__django-13321.notebook_run_2 removed.
2025-04-29 13:29:32,808 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13321:latest...
2025-04-29 13:29:33,493 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13321:latest removed.
