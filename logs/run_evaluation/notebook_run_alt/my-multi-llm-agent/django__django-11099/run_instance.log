2025-04-29 10:41:29,593 - INFO - Creating container for django__django-11099...
2025-04-29 10:41:30,331 - INFO - Container for django__django-11099 created: fe4755ca0103b6c5db87ed205e9fca279b22307ecc92e9a22469ec9cba69c624
2025-04-29 10:41:30,793 - INFO - Container for django__django-11099 started: fe4755ca0103b6c5db87ed205e9fca279b22307ecc92e9a22469ec9cba69c624
2025-04-29 10:41:30,794 - INFO - Intermediate patch for django__django-11099 written to logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\patch.diff, now applying to container...
2025-04-29 10:41:30,954 - INFO - Failed to apply patch to container: git apply --verbose
2025-04-29 10:41:31,023 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-04-29 10:41:31,090 - INFO - Failed to apply patch to container: patch --batch --binary --fuzz=5 -p1 -i
2025-04-29 10:41:31,090 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

2025-04-29 10:41:31,186 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 10:41:31,188 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,188 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,188 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,189 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,190 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,191 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,192 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,192 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,193 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,194 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,195 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,196 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,197 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,198 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,199 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,200 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,201 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,202 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,203 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,204 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,205 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,206 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,207 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,209 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,211 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,213 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,214 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,215 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,216 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,216 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,217 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,217 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,218 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,218 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,218 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,219 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,220 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,221 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,222 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,223 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,223 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,223 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,223 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,223 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,226 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,226 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,226 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,227 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,227 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,228 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,229 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,229 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,230 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,231 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,232 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,233 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,234 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,235 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,236 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,237 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,238 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,238 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,239 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,239 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,240 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,240 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,241 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,241 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,242 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,242 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,243 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,244 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,244 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,244 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,245 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,245 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,245 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,247 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,247 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,248 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,249 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,249 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,250 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,251 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,252 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,253 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,254 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,255 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,256 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,256 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,257 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,258 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,259 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,260 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,261 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,264 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,266 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,267 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,268 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,269 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,269 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,270 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,271 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,272 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,273 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,274 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,275 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,275 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,276 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,277 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,278 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,279 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,280 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,280 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,281 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,282 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,282 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,282 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,283 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,284 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,285 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,286 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,287 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,288 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,290 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,291 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,420 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <exception str() failed>

2025-04-29 10:41:31,420 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,421 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,422 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,423 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,424 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,424 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,425 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,426 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,426 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,427 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,428 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,429 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,430 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,431 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,432 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,434 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,436 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,437 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,438 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,439 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,440 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,441 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,442 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,444 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,445 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,445 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,445 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,446 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,447 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,450 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,454 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,463 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,473 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,478 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,479 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,480 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,483 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,483 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,483 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,483 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,483 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,486 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,486 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,486 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,486 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,489 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,489 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,489 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,491 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,491 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,491 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,491 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,494 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,502 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,503 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,507 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,507 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,508 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,508 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,508 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,510 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,510 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,511 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,511 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,512 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,513 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,513 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,514 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,515 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,516 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,517 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,518 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,519 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,522 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,523 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,526 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,527 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,528 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,534 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Traceback (most recent call last):
  File "C:\Nishant\Work\BITS - Engineering\2-2\LLM\Proj\SWE-bench\swebench\harness\run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11099: >>>>> Patch Apply Failed:
patching file django/contrib/auth/validators.py
Hunk #1 FAILED at 7 (different line endings).
Hunk #2 FAILED at 16 (different line endings).
2 out of 2 hunks FAILED -- saving rejects to file django/contrib/auth/validators.py.rej
patch unexpectedly ends in middle of line

Check (logs\run_evaluation\notebook_run_alt\my-multi-llm-agent\django__django-11099\run_instance.log) for more information.

2025-04-29 10:41:31,535 - INFO - Attempting to stop container sweb.eval.django__django-11099.notebook_run_alt...
2025-04-29 10:41:47,402 - INFO - Attempting to remove container sweb.eval.django__django-11099.notebook_run_alt...
2025-04-29 10:41:47,452 - INFO - Container sweb.eval.django__django-11099.notebook_run_alt removed.
2025-04-29 10:41:47,452 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-11099:latest...
2025-04-29 10:41:48,046 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-11099:latest removed.
