2025-05-08 15:30:19,642 - INFO - Creating container for django__django-13551...
2025-05-08 15:30:19,882 - INFO - Container for django__django-13551 created: 7079d9395290568b0662e3bc54359356573b3d6c008847506169dfa5af0273a2
2025-05-08 15:30:20,346 - INFO - Container for django__django-13551 started: 7079d9395290568b0662e3bc54359356573b3d6c008847506169dfa5af0273a2
2025-05-08 15:30:20,360 - INFO - Intermediate patch for django__django-13551 written to logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/patch.diff, now applying to container...
2025-05-08 15:30:20,802 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-08 15:30:20,972 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-08 15:30:21,110 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-08 15:30:21,113 - INFO - >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

2025-05-08 15:30:21,407 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 15:30:21,408 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,409 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,410 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,410 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,411 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,411 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,411 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,412 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,412 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,413 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,413 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,414 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,415 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,416 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,416 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,417 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,417 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,418 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,418 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,419 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,419 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,420 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,420 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,421 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,421 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,422 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,422 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,423 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,423 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,424 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,424 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,425 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,426 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,428 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,429 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,430 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,431 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,432 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,433 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,434 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,435 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,436 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,437 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,439 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,440 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,441 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,442 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,443 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,444 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,445 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,446 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,447 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,448 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,449 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,450 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,451 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,452 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,453 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,454 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,455 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,459 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,460 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,461 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,462 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,464 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,465 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,466 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,467 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,468 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,469 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,470 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,471 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,472 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,473 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,474 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,475 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,476 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,477 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,478 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,479 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,480 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,772 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 15:30:21,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,773 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,774 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,774 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,775 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,775 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,776 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,777 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,778 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,779 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,780 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,781 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,781 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,781 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,782 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,783 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,784 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,785 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,786 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,787 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,787 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,788 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,789 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,791 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,792 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,798 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,801 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,802 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,802 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,803 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,804 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,804 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,805 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,805 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,806 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,807 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,808 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,808 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,809 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,809 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,810 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,810 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,811 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,811 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,812 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,813 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,814 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,815 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,815 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,816 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,817 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,818 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,819 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,820 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,821 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,822 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,823 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,824 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,825 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,826 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,827 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,828 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,829 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,830 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,831 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,832 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,833 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,834 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,835 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,836 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,837 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,838 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,839 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,840 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,841 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,842 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-13551: >>>>> Patch Apply Failed:
patching file django/contrib/auth/tokens.py
Hunk #1 FAILED at 43.
1 out of 1 hunk FAILED -- saving rejects to file django/contrib/auth/tokens.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-13551/run_instance.log) for more information.

2025-05-08 15:30:21,842 - INFO - Attempting to stop container sweb.eval.django__django-13551.trial_run_corrected_mode_8...
2025-05-08 15:30:37,655 - INFO - Attempting to remove container sweb.eval.django__django-13551.trial_run_corrected_mode_8...
2025-05-08 15:30:38,562 - INFO - Container sweb.eval.django__django-13551.trial_run_corrected_mode_8 removed.
2025-05-08 15:30:38,563 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-13551:latest...
2025-05-08 15:30:39,557 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-13551:latest removed.
