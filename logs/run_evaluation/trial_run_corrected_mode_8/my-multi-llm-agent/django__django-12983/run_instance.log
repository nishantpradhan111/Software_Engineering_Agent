2025-05-08 15:27:42,646 - INFO - Creating container for django__django-12983...
2025-05-08 15:27:43,895 - INFO - Container for django__django-12983 created: 76a736c664cc484f7fbf606184f74a83e47102fc9f15d9a5593bc64e748c988a
2025-05-08 15:27:44,390 - INFO - Container for django__django-12983 started: 76a736c664cc484f7fbf606184f74a83e47102fc9f15d9a5593bc64e748c988a
2025-05-08 15:27:44,396 - INFO - Intermediate patch for django__django-12983 written to logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/patch.diff, now applying to container...
2025-05-08 15:27:44,638 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-08 15:27:44,759 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-08 15:27:44,878 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-08 15:27:44,878 - INFO - >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

2025-05-08 15:27:45,243 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 15:27:45,244 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,245 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,246 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,247 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,248 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,251 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,252 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,253 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,254 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,255 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,256 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,257 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,258 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,259 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,260 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,261 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,262 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,263 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,268 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,270 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,271 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,271 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,272 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,273 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,274 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,276 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,277 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,278 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,279 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,280 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,281 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,286 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,287 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,287 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,289 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,289 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,290 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,290 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,291 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,292 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,292 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,294 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,294 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,295 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,295 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,297 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,297 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,298 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,298 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,301 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,301 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,302 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,302 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,303 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,303 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,303 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,304 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,304 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,306 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,306 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,308 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,308 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,309 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,309 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,310 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,310 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,311 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,311 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,313 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,313 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,314 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,315 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,315 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,501 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-08 15:27:45,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,504 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,505 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,506 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,507 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,508 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,509 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,511 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,512 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,513 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,514 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,514 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,516 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,517 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,517 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,518 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,518 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,519 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,519 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,520 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,521 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,521 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,522 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,522 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,523 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,524 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,524 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,524 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,525 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,525 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,526 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,526 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,527 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,528 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,528 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,531 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,531 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,532 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,535 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,536 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,537 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,538 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,538 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,539 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,539 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,540 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,541 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,542 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,542 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,543 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,544 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,544 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,545 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,546 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,547 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,548 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,549 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,550 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,550 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,551 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,552 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,553 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,554 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,555 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,555 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,556 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,557 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,558 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,559 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,559 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,560 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,560 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,561 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,561 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,562 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,562 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,563 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,563 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,564 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,564 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,567 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,568 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,572 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,573 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,574 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,575 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,576 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,577 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,578 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,579 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,579 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,580 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,581 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-12983: >>>>> Patch Apply Failed:
patching file tests/utils_tests/test_text.py
Hunk #1 FAILED at 195.
patch unexpectedly ends in middle of line
1 out of 1 hunk FAILED -- saving rejects to file tests/utils_tests/test_text.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/trial_run_corrected_mode_8/my-multi-llm-agent/django__django-12983/run_instance.log) for more information.

2025-05-08 15:27:45,583 - INFO - Attempting to stop container sweb.eval.django__django-12983.trial_run_corrected_mode_8...
2025-05-08 15:28:01,098 - INFO - Attempting to remove container sweb.eval.django__django-12983.trial_run_corrected_mode_8...
2025-05-08 15:28:01,185 - INFO - Container sweb.eval.django__django-12983.trial_run_corrected_mode_8 removed.
2025-05-08 15:28:01,185 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-12983:latest...
2025-05-08 15:28:01,903 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-12983:latest removed.
