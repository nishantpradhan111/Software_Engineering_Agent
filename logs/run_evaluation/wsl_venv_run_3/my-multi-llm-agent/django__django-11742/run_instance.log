2025-05-03 21:31:53,465 - INFO - Creating container for django__django-11742...
2025-05-03 21:31:53,992 - INFO - Container for django__django-11742 created: 30b1d43f1f0b2b9540b337b3512f7757f3faad67dd84dc3fc6107e84bf49215b
2025-05-03 21:31:54,253 - INFO - Container for django__django-11742 started: 30b1d43f1f0b2b9540b337b3512f7757f3faad67dd84dc3fc6107e84bf49215b
2025-05-03 21:31:54,260 - INFO - Intermediate patch for django__django-11742 written to logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/patch.diff, now applying to container...
2025-05-03 21:31:54,428 - INFO - Failed to apply patch to container: git apply --verbose
2025-05-03 21:31:54,496 - INFO - Failed to apply patch to container: git apply --verbose --reject
2025-05-03 21:31:54,561 - INFO - Failed to apply patch to container: patch --batch --fuzz=5 -p1 -i
2025-05-03 21:31:54,561 - INFO - >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

2025-05-03 21:31:54,895 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 21:31:54,896 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,896 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,896 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,896 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,897 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,897 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,897 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,898 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,898 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,898 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,899 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,899 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,899 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,900 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,900 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,901 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,901 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,902 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,902 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,903 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,903 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,904 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,905 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,905 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,906 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,906 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,906 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,907 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,908 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,909 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,910 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,911 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,912 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,913 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,914 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,915 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,916 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,917 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,918 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,919 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,920 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,921 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,921 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,921 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,922 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,923 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,924 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,925 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,925 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,926 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,927 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,928 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,929 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,930 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,931 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,932 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,932 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,933 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,934 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:54,935 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,282 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: <unprintable EvaluationError object>

2025-05-03 21:31:55,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,283 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,284 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,285 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,286 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,286 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,286 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,287 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,287 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,287 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,288 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,289 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,289 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,289 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,290 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,290 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,290 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,291 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,291 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,291 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,292 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,292 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,292 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,293 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,293 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,293 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,294 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,294 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,294 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,295 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,295 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,295 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,296 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,297 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,297 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,297 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,298 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,298 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,298 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,299 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,300 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,301 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,301 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,302 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,302 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,302 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,303 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,303 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,304 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,304 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,304 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,305 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,306 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,306 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,306 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,307 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,308 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,308 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,308 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,309 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,309 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,309 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,310 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,310 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,310 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,311 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,311 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,311 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,312 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,313 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,313 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,313 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,314 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,314 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,314 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,315 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,316 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,317 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,317 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,317 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,318 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,318 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,318 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,319 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,319 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,320 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,320 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,320 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,320 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,321 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,321 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,321 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,322 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,322 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,322 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,323 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,323 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,323 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,324 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,324 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,326 - INFO - Traceback (most recent call last):
  File "/mnt/c/Nishant/Work/BITS - Engineering/2-2/LLM/Proj/SWE-bench/swebench/harness/run_evaluation.py", line 170, in run_instance
    raise EvaluationError(
swebench.harness.utils.EvaluationError: django__django-11742: >>>>> Patch Apply Failed:
patching file django/db/models/fields/__init__.py
Hunk #1 FAILED at 270.
1 out of 1 hunk FAILED -- saving rejects to file django/db/models/fields/__init__.py.rej
patch unexpectedly ends in middle of line

Check (logs/run_evaluation/wsl_venv_run_3/my-multi-llm-agent/django__django-11742/run_instance.log) for more information.

2025-05-03 21:31:55,327 - INFO - Attempting to stop container sweb.eval.django__django-11742.wsl_venv_run_3...
2025-05-03 21:32:11,082 - INFO - Attempting to remove container sweb.eval.django__django-11742.wsl_venv_run_3...
2025-05-03 21:32:11,115 - INFO - Container sweb.eval.django__django-11742.wsl_venv_run_3 removed.
2025-05-03 21:32:11,116 - INFO - Attempting to remove image swebench/sweb.eval.x86_64.django_1776_django-11742:latest...
2025-05-03 21:32:12,427 - INFO - Image swebench/sweb.eval.x86_64.django_1776_django-11742:latest removed.
