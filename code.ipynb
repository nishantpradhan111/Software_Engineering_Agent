{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de96daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import Dict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f182190",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro-exp-03-25\",\n",
    "    google_api_key=\"AIzaSyCs6KuYNBDLA9uQxgoZbhtU53ha43waKms\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e545c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_patch_format(patch):\n",
    "    \"\"\"\n",
    "    Ensures a patch is in valid unified-diff format. If malformed, uses an LLM to correct it.\n",
    "    \"\"\"\n",
    "    # quick heuristic: must start with '--- a/' and contain '@@'\n",
    "    if not patch.startswith('--- a/') or '@@' not in patch:\n",
    "        prompt = f\"\"\"You are a software engineer fixing an automated code patch.\n",
    "\n",
    "The following patch is malformed or incomplete: {patch}\n",
    "\n",
    "Please return a corrected patch using valid unified-diff format:\n",
    "- It must start with '--- a/...' and '+++ b/...'\n",
    "- It must contain at least one valid hunk beginning with '@@'\n",
    "- Do not include explanations, comments, markdown, or any text outside the patch.\n",
    "- Your response must be a pure, corrected unified diff.\n",
    "- It should be in raw unified-diff format, without any markdown wrapping\n",
    "\n",
    "Return a minimal valid patch only.\"\"\"\n",
    "        feedback = llm([HumanMessage(content=prompt)]).content\n",
    "        return feedback\n",
    "    return patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f4d2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the reflection loop function\n",
    "def generate_patch(instance: Dict, llm, max_reflections: int = 3):\n",
    "    \"\"\"\n",
    "    Generate a patch with iterative self-reflection using an LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    problem = instance['problem_statement']\n",
    "\n",
    "    # Initial patch generation (O1-style prompt)\n",
    "    initial_prompt = f\"\"\"You are an expert software engineer.\n",
    "\n",
    "Below is a problem description from a GitHub issue:\n",
    "{problem}\n",
    "\n",
    "Generate a fix for this issue in valid unified-diff format.\n",
    "Your output must:\n",
    "- Begin with '--- a/...' and '+++ b/...'\n",
    "- Contain at least one '@@' hunk\n",
    "- NOT include explanations, comments, or markdown\n",
    "- Be minimal and syntactically correct\n",
    "\n",
    "Output only the patch.\"\"\"\n",
    "    current_patch = llm([HumanMessage(content=initial_prompt)]).content\n",
    "\n",
    "    # Reflection loop\n",
    "    for i in range(max_reflections):\n",
    "        reflection_prompt = f\"\"\"You are reviewing the following patch:\n",
    "{current_patch}\n",
    "The patch was intended to fix this issue:\n",
    "\n",
    "Check:\n",
    "- Does it correctly address the issue?\n",
    "- Is it syntactically valid unified-diff (starts with --- a/, contains @@)?\n",
    "- Can it be applied cleanly (no formatting or logical errors)?\n",
    "\n",
    "If any issue is found, rewrite the patch and return only the corrected unified diff. Do not include any explanations or markdown.\"\"\"\n",
    "        current_patch = llm([HumanMessage(content=reflection_prompt)]).content\n",
    "\n",
    "    current_patch = refine_patch_format(current_patch)\n",
    "\n",
    "    return current_patch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9871e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['repo', 'instance_id', 'base_commit', 'patch', 'test_patch', 'problem_statement', 'hints_text', 'created_at', 'version', 'FAIL_TO_PASS', 'PASS_TO_PASS', 'environment_setup_commit']\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"princeton-nlp/SWE-bench_Lite\", split=\"test\")\n",
    "print(dataset.column_names)\n",
    "predictions = []\n",
    "for i in range (2):\n",
    "    instance = dataset[i]\n",
    "    patch = generate_patch(instance,llm)\n",
    "    predictions.append({\n",
    "        \"instance_id\": instance[\"instance_id\"],\n",
    "        \"model\": \"my-multi-llm-agent\",\n",
    "        \"prediction\": patch\n",
    "    })\n",
    "    print(i+1)\n",
    "\n",
    "with open(\"my_preds.jsonl\", \"w\") as f:\n",
    "    for p in predictions:\n",
    "        f.write(json.dumps(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af758100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"my_preds.jsonl\") as fin, open(\"fixed_preds.jsonl\", \"w\") as fout:\n",
    "    for line in fin:\n",
    "        rec = json.loads(line)\n",
    "        # rename the keys the harness expects\n",
    "        rec[\"model_name_or_path\"] = rec.pop(\"model\")\n",
    "        rec[\"model_patch\"]       = rec.pop(\"prediction\")\n",
    "        fout.write(json.dumps(rec) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
