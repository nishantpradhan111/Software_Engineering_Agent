{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0b37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import Dict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18267381",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=\"AIzaSyC05prna34uJxLl9xgnLJUfBphgYKKQlc0\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-chat\",\n",
    "#     google_api_key=\"sk-fd9f23bb13344af497899e25ce4327aa\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4787b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5deac33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_initial_prompt(problem: str, context: Dict) -> str:\n",
    "    base_info = context.get('base_commit_info', '')\n",
    "    test_snippet = context.get('failing_test', '')\n",
    "    return (\n",
    "        f\"\"\"You are an expert software engineer.\n",
    "\n",
    "Below is a problem description from a GitHub issue:\n",
    "{problem}\n",
    "Make sure you are checking the correct base commit version or else the patch you generate will be invalid. You can check that from reading this {instance}. \n",
    "\n",
    "Generate a fix for this issue in valid unified-diff format.\n",
    "\n",
    "Make sure to fix each and every error. Go Through all the lines pertaining to the problem and check. Try simulating a test case yourself to see if the code you have written gives ocrrect output.\n",
    "Make sure to check the file path and make sure it is correct to avoid context mismatch errors \n",
    "\n",
    "Your output must:\n",
    "- Be in pure raw unified diff format. There should be no wrappers like the ```\n",
    "- Begin with '--- a/...' and '+++ b/...'\n",
    "- Contain at least one '@@' hunk\n",
    "- NOT include explanations, comments, or markdown\n",
    "- Be minimal and syntactically correct\n",
    "- Make sure the code which you are changing (the - part in the code) is actually there\n",
    "- Check if the indices of the line of code and the actual code in the repository actually match\n",
    "\n",
    "If the above does not work, try again.\n",
    "\n",
    "Make sure you are checking the correct base commit version or else the patch you generate will be invalid, here is all the relevant info {instance}\n",
    "\n",
    "Make sure to fix each and every error. Go Through all the lines pertaining to the problem and check. Try simulating a test case yourself to see if the code you have written gives ocrrect output.\n",
    "Make sure to check the file path and make sure it is correct to avoid context mismatch errors \n",
    "\n",
    "Output only the patch.\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e51a5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reflection_prompt(patch: str, problem: str) -> str:\n",
    "    return (\n",
    "        f\"\"\"\n",
    "Review this patch intended to fix the issue:\n",
    "\n",
    "{patch}\n",
    "\n",
    "Checks:\n",
    "- Valid unified diff syntax (--- a/, '@@', '+' and '-' marks)\n",
    "- Addresses the problem correctly\n",
    "- Apply cleanly without context mismatches\n",
    "\n",
    "If you find issues, rewrite and return only the corrected unified diff (no explanations).\n",
    "\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e6e6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_diff(patch: str) -> bool:\n",
    "    return patch.strip().startswith('--- a/') and '@@' in patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ede92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context(instance: Dict) -> Dict:\n",
    "    # Only include necessary fields\n",
    "    return {\n",
    "        'base_commit_info': instance.get('base_commit_info', ''),\n",
    "        'failing_test': instance.get('test_patch', '')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e57a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_patch(problem: str, context: Dict, llm) -> str:\n",
    "    prompt = build_initial_prompt(problem, context)\n",
    "    patch = llm([HumanMessage(content=prompt)]).content\n",
    "    logger.info(\"Initial patch generated\")\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60effa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reflect_and_improve(patch: str, problem: str, max_iter: int, llm) -> str:\n",
    "    for i in range(max_iter):\n",
    "        if is_valid_diff(patch):\n",
    "            logger.info(f\"Patch passed validation on iteration {i}\")\n",
    "            break\n",
    "        prompt = build_reflection_prompt(patch, problem)\n",
    "        patch = llm([HumanMessage(content=prompt)]).content\n",
    "        logger.info(f\"Reflection iteration {i+1} completed\")\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4029132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refine_patch_format(patch: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures a patch is in valid unified-diff format. If malformed, uses an LLM to correct it.\n",
    "    \"\"\"\n",
    "    # quick heuristic: must start with '--- a/' and contain '@@'\n",
    "    if not patch.startswith('--- a/') or '@@' not in patch:\n",
    "        prompt = f\"\"\"You are a software engineer fixing an automated code patch.\n",
    "\n",
    "The following patch is malformed or incomplete: {patch}\n",
    "\n",
    "Please return a corrected patch using valid unified-diff format:\n",
    "- It must start with '--- a/...' and '+++ b/...'\n",
    "- It must contain at least one valid hunk beginning with '@@'\n",
    "- Do not include explanations, comments, markdown, or any text outside the patch.\n",
    "- Your response must be a pure, corrected unified diff.\n",
    "- It should be in raw unified-diff format, without any markdown wrapping\n",
    "\n",
    "Return a minimal valid patch only.\"\"\"\n",
    "        feedback = llm([HumanMessage(content=prompt)]).content\n",
    "        return feedback\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db05597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patch(instance: Dict, llm, max_reflections: int = 3) -> str:\n",
    "    problem = instance['problem_statement']\n",
    "    context = extract_context(instance)\n",
    "\n",
    "    # Stage 1: initial patch\n",
    "    patch = generate_initial_patch(problem, context, llm)\n",
    "\n",
    "    # Stage 2: iterative self-reflection\n",
    "    patch = reflect_and_improve(patch, problem, max_reflections, llm)\n",
    "\n",
    "    # Stage 3: final cleanup\n",
    "    return refine_patch_format(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e417ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['repo', 'instance_id', 'base_commit', 'test_patch', 'problem_statement', 'hints_text', 'created_at', 'version', 'FAIL_TO_PASS', 'PASS_TO_PASS', 'environment_setup_commit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initial patch generated\n",
      "INFO:__main__:Reflection iteration 1 completed\n",
      "INFO:__main__:Reflection iteration 2 completed\n",
      "INFO:__main__:Reflection iteration 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"princeton-nlp/SWE-bench_Lite\", split=\"test\")\n",
    "dataset = dataset.remove_columns(\"patch\")\n",
    "dataset = dataset.remove_columns(\"test_patch\")\n",
    "dataset = dataset.shuffle()\n",
    "print(dataset.column_names)\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    instance = dataset[i]\n",
    "    patch = generate_patch(instance,llm)\n",
    "    predictions.append({\n",
    "        \"instance_id\": instance[\"instance_id\"],\n",
    "        \"model_name_or_path\": \"my-multi-llm-agent\",\n",
    "        \"model_patch\": patch\n",
    "    })\n",
    "    print(i+1)\n",
    "    i += 1\n",
    "\n",
    "with open(\"my_preds.jsonl\", \"w\") as f:\n",
    "    for p in predictions:\n",
    "        f.write(json.dumps(p) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
